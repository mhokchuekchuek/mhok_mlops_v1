{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19defff-e5e1-4de3-8568-d5a2ebc83b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "X_test = pd.read_csv(\"/ml_data/X_test.csv\").drop(columns = \"Unnamed: 0\")\n",
    "X_test[\"built_year\"] = X_test[\"built_year\"].astype('category')\n",
    "y_test = pd.read_csv(\"/ml_data/y_test.csv\").drop(columns = \"Unnamed: 0\")\n",
    "X_train_1 = pd.read_csv(\"/ml_data/transform.csv\").drop(columns = [\"Unnamed: 0\"])\n",
    "feature_names = list(X_test.columns)\n",
    "model = joblib.load(\"/artifact/mlruns/286978358198217900/1e69c74027c745b6819ce40a8f6de458/artifacts/model/model.pkl\")\n",
    "preprocessor_1 = joblib.load(\"/save_pipeline/pipeline_09_01_23_02:13:43.pkl\")\n",
    "preprocessor_1_ = joblib.load(\"/save_pipeline/pipeline_09_01_23_02:13:43.pkl\")\n",
    "preprocessor_2 = preprocessor_1_.fit(X_test)\n",
    "\n",
    "def check_cols(preprocessor):\n",
    "    all_columns = []\n",
    "    for i in range(len(preprocessor.transformers_)):\n",
    "        if preprocessor.transformers_[i][0] == \"num\":\n",
    "            all_columns.extend(preprocessor.transformers[i][2])\n",
    "        else:\n",
    "            for j in range(len(preprocessor.transformers_[1][1].steps)):\n",
    "                for array_ja in preprocessor.transformers_[1][1].steps[j][1].categories_:\n",
    "                    all_columns.extend(list(array_ja))\n",
    "    return all_columns\n",
    "\n",
    "def check_type(df)-> list[str]:\n",
    "    df_columns = list(df.columns)\n",
    "    numeric = []\n",
    "    catagories = []\n",
    "    for values in df.columns:\n",
    "        if df[values].dtypes == int or df[values].dtypes == float or df[values].dtypes == 'uint8':\n",
    "            numeric.append(values)\n",
    "        else:\n",
    "            catagories.append(values)\n",
    "    return numeric\n",
    "\n",
    "def insert_cols(prepro_1, prepro_2):\n",
    "    num = []\n",
    "    j = -1\n",
    "    for i in check_cols(prepro_1):\n",
    "        j += 1\n",
    "        if i not in check_cols(prepro_2):\n",
    "            num.append(j)\n",
    "    return num\n",
    "\n",
    "\n",
    "def save_to_csv():\n",
    "    all_columns = check_cols(preprocessor_1)\n",
    "    explainer = shap.TreeExplainer(model[0] ,feature_names = all_columns)\n",
    "    count_num = len(check_type(X_test))\n",
    "    for_pandas = preprocessor_1.fit_transform(X_test)\n",
    "    X_test_ja = pd.DataFrame(np.insert(for_pandas, insert_cols(preprocessor_1, preprocessor_2), 0, axis = 1), columns = all_columns)\n",
    "    X_test_ja.iloc[:,:count_num] = preprocessor_1.transformers_[0][1].steps[1][1].inverse_transform(X_test_ja.iloc[:,:count_num])\n",
    "    shap_values = explainer.shap_values(np.insert(for_pandas, insert_cols(preprocessor_1, preprocessor_2), 0, axis = 1), y = y_test.values)\n",
    "    global_values = pd.DataFrame(np.reshape(sum(np.abs(shap_values))/len(sum(np.abs(shap_values))), newshape = (1,-1)), columns = all_columns)\n",
    "    train_dependency_values = pd.DataFrame(np.abs(shap_values), columns = [\"importance_values_\" + i for i in all_columns])\n",
    "    pd.concat([train_dependency_values, X_test_ja], axis = 1).to_csv(\"/model_interpret/local.csv\")\n",
    "    global_values.to_csv(\"/model_interpret/global.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02489934-026c-40c6-b8be-2e801a9c9610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.iloc[:,96].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23081ea-0d36-47cd-8181-a16ccf3fd89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_cols(preprocessor_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea83e827-7b5c-4208-9882-10bc863e68da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 97, 98, 126]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_cols(preprocessor_1, preprocessor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39cba3bb-8a38-41c9-9dc9-d017a53a4d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n"
     ]
    }
   ],
   "source": [
    "all_columns = check_cols(preprocessor_1)\n",
    "add_cols = insert_cols(preprocessor_1, preprocessor_2)\n",
    "explainer = shap.TreeExplainer(model[0] ,feature_names = all_columns)\n",
    "count_num = len(check_type(X_test))\n",
    "for_pandas = preprocessor_1.fit_transform(X_test)\n",
    "X_test_ja = pd.DataFrame(np.insert(for_pandas, add_cols, 0, axis = 1), columns = all_columns)\n",
    "X_test_ja.iloc[:,:count_num] = preprocessor_1.transformers_[0][1].steps[1][1].inverse_transform(X_test_ja.iloc[:,:count_num])\n",
    "shap_values = explainer.shap_values(np.insert(for_pandas, add_cols, 0, axis = 1))\n",
    "global_values = pd.DataFrame(np.reshape(sum(np.abs(shap_values))/len(sum(np.abs(shap_values))), newshape = (1,-1)), columns = all_columns)\n",
    "train_dependency_values = pd.DataFrame(np.abs(shap_values), columns = [\"importance_values_\" + str(i) for i in all_columns])\n",
    "# pd.concat([train_dependency_values, X_test_ja], axis = 1).to_csv(\"/model_interpret/local.csv\")\n",
    "# global_values.to_csv(\"/model_interpret/global.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074a1f37-a4b0-4195-9b71-cabb45f50eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d96b0b-4091-4c9a-a9fb-c71ccb2baf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1274, 134)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_pandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63a9145-3ddc-405f-9c9b-17ccec67b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(insert_cols(preprocessor_1, preprocessor_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a05499-82bc-4564-a7d9-21e4ed04a8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
